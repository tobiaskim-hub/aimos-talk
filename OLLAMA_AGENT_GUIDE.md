# ğŸ¤– Ollamaë¥¼ AI ê°œë°œìë¡œ ë§Œë“¤ê¸° (ì™„ì „ ê°€ì´ë“œ)

> **ëª©í‘œ**: Ollama + Qwenì„ Claudeì²˜ëŸ¼ íŒŒì¼ ì½ê³ , ì½”ë“œ ì‘ì„±í•˜ê³ , Git ì»¤ë°‹í•˜ëŠ” AI ê°œë°œìë¡œ ë§Œë“¤ê¸°

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œë… ì´í•´](#ê°œë…-ì´í•´)
2. [ë°©ë²• ë¹„êµ](#ë°©ë²•-ë¹„êµ)
3. [ë°©ë²• 1: ì§ì ‘ êµ¬í˜„](#ë°©ë²•-1-ì§ì ‘-êµ¬í˜„)
4. [ë°©ë²• 2: LangChain ì‚¬ìš©](#ë°©ë²•-2-langchain-ì‚¬ìš©)
5. [ë°©ë²• 3: Open WebUI ì‚¬ìš©](#ë°©ë²•-3-open-webui-ì‚¬ìš©)
6. [ë°©ë²• 4: Continue.dev ì‚¬ìš©](#ë°©ë²•-4-continuedev-ì‚¬ìš©)
7. [ë°©ë²• 5: Aider ì‚¬ìš©](#ë°©ë²•-5-aider-ì‚¬ìš©)
8. [ì‹¤ì „ í”„ë¡œì íŠ¸](#ì‹¤ì „-í”„ë¡œì íŠ¸)

---

## ğŸ§  ê°œë… ì´í•´

### Claude (GenS) vs Ollama ì°¨ì´

```
Claude (GenS):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude LLM     â”‚  "README.mdë¥¼ ì½ì–´ì¤˜"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë„êµ¬ ì‹œìŠ¤í…œ    â”‚
â”‚  - Read         â”‚  íŒŒì¼ ì½ê¸° â†’ ê²°ê³¼ ë°˜í™˜
â”‚  - Write        â”‚
â”‚  - Bash         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ollamaë§Œ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama LLM     â”‚  "íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ cat README.md ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         âŒ ì§ì ‘ ì‹¤í–‰ ì•ˆ í•¨!

Ollama + ë„êµ¬:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama LLM     â”‚  "README.mdë¥¼ ì½ì–´ì¤˜"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì§ì ‘ ë§Œë“  ë„êµ¬ â”‚
â”‚  - readFile()   â”‚  íŒŒì¼ ì½ê¸° â†’ ê²°ê³¼ ë°˜í™˜ âœ…
â”‚  - writeFile()  â”‚
â”‚  - runCommand() â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš–ï¸ ë°©ë²• ë¹„êµ

| ë°©ë²• | ë‚œì´ë„ | ìœ ì—°ì„± | ê¸°ëŠ¥ | ì¶”ì²œë„ |
|------|--------|--------|------|--------|
| **1. ì§ì ‘ êµ¬í˜„** | â­â­â­â­ ì–´ë ¤ì›€ | â­â­â­â­â­ ìµœê³  | ëª¨ë“  ê¸°ëŠ¥ | â­â­â­ |
| **2. LangChain** | â­â­â­ ë³´í†µ | â­â­â­â­ ë†’ìŒ | ëŒ€ë¶€ë¶„ | â­â­â­â­â­ |
| **3. Open WebUI** | â­ ì‰¬ì›€ | â­â­ ë‚®ìŒ | ê¸°ë³¸ì  | â­â­â­â­ |
| **4. Continue.dev** | â­ ì‰¬ì›€ | â­â­â­ ë³´í†µ | ì½”ë“œ ì¤‘ì‹¬ | â­â­â­â­ |
| **5. Aider** | â­â­ ì‰¬ì›€ | â­â­â­ ë³´í†µ | Git í†µí•© | â­â­â­â­â­ |

---

## ğŸ› ï¸ ë°©ë²• 1: ì§ì ‘ êµ¬í˜„

### ê°œìš”

ì™„ì „íˆ ì²˜ìŒë¶€í„° ë§Œë“¤ì–´ì„œ ìµœëŒ€ ì œì–´ê¶Œ í™•ë³´!

### í”„ë¡œì íŠ¸ ìƒì„±

```bash
mkdir ollama-agent
cd ollama-agent
npm init -y
npm install typescript ts-node @types/node
npm install axios
npx tsc --init
```

### í•µì‹¬ ì½”ë“œ

#### `src/tools.ts` - ë„êµ¬ ì •ì˜

```typescript
import { readFileSync, writeFileSync, existsSync, mkdirSync } from 'fs'
import { exec } from 'child_process'
import { promisify } from 'util'

const execAsync = promisify(exec)

export interface Tool {
  name: string
  description: string
  parameters: any
  execute: (...args: any[]) => Promise<string>
}

export const tools: Tool[] = [
  {
    name: 'read_file',
    description: 'íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤',
    parameters: {
      path: 'string - íŒŒì¼ ê²½ë¡œ'
    },
    execute: async (path: string) => {
      try {
        const content = readFileSync(path, 'utf-8')
        return `íŒŒì¼ ë‚´ìš©:\n${content}`
      } catch (error) {
        return `ì—ëŸ¬: íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ${error.message}`
      }
    }
  },
  
  {
    name: 'write_file',
    description: 'íŒŒì¼ì— ë‚´ìš©ì„ ì”ë‹ˆë‹¤',
    parameters: {
      path: 'string - íŒŒì¼ ê²½ë¡œ',
      content: 'string - íŒŒì¼ ë‚´ìš©'
    },
    execute: async (path: string, content: string) => {
      try {
        writeFileSync(path, content, 'utf-8')
        return `íŒŒì¼ ì‘ì„± ì™„ë£Œ: ${path}`
      } catch (error) {
        return `ì—ëŸ¬: íŒŒì¼ì„ ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ${error.message}`
      }
    }
  },
  
  {
    name: 'run_command',
    description: 'ì‰˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤',
    parameters: {
      command: 'string - ì‹¤í–‰í•  ëª…ë ¹ì–´'
    },
    execute: async (command: string) => {
      try {
        const { stdout, stderr } = await execAsync(command)
        return stdout || stderr || 'ëª…ë ¹ì–´ ì‹¤í–‰ ì™„ë£Œ'
      } catch (error) {
        return `ì—ëŸ¬: ${error.message}`
      }
    }
  },
  
  {
    name: 'list_files',
    description: 'ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤',
    parameters: {
      path: 'string - ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸: .)'
    },
    execute: async (path: string = '.') => {
      try {
        const { stdout } = await execAsync(`ls -la ${path}`)
        return stdout
      } catch (error) {
        return `ì—ëŸ¬: ${error.message}`
      }
    }
  },
  
  {
    name: 'git_status',
    description: 'Git ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤',
    parameters: {},
    execute: async () => {
      try {
        const { stdout } = await execAsync('git status')
        return stdout
      } catch (error) {
        return `ì—ëŸ¬: ${error.message}`
      }
    }
  },
  
  {
    name: 'git_commit',
    description: 'Git ì»¤ë°‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤',
    parameters: {
      message: 'string - ì»¤ë°‹ ë©”ì‹œì§€'
    },
    execute: async (message: string) => {
      try {
        await execAsync('git add .')
        const { stdout } = await execAsync(`git commit -m "${message}"`)
        return stdout
      } catch (error) {
        return `ì—ëŸ¬: ${error.message}`
      }
    }
  }
]
```

#### `src/llm.ts` - Ollama í†µì‹ 

```typescript
import axios from 'axios'

export interface OllamaOptions {
  model: string
  baseUrl: string
}

export class OllamaClient {
  private model: string
  private baseUrl: string
  
  constructor(options: OllamaOptions) {
    this.model = options.model
    this.baseUrl = options.baseUrl
  }
  
  async generate(prompt: string): Promise<string> {
    try {
      const response = await axios.post(`${this.baseUrl}/api/generate`, {
        model: this.model,
        prompt: prompt,
        stream: false
      })
      
      return response.data.response
    } catch (error) {
      throw new Error(`Ollama ì—ëŸ¬: ${error.message}`)
    }
  }
  
  async chat(messages: Array<{role: string, content: string}>): Promise<string> {
    try {
      const response = await axios.post(`${this.baseUrl}/api/chat`, {
        model: this.model,
        messages: messages,
        stream: false
      })
      
      return response.data.message.content
    } catch (error) {
      throw new Error(`Ollama ì—ëŸ¬: ${error.message}`)
    }
  }
}
```

#### `src/agent.ts` - Agent ë©”ì¸ ë¡œì§

```typescript
import { OllamaClient } from './llm'
import { tools, Tool } from './tools'

export class OllamaAgent {
  private llm: OllamaClient
  private conversationHistory: Array<{role: string, content: string}> = []
  
  constructor(model: string = 'qwen2.5:7b', baseUrl: string = 'http://localhost:11434') {
    this.llm = new OllamaClient({ model, baseUrl })
  }
  
  private getToolsDescription(): string {
    return tools.map(tool => {
      const params = Object.entries(tool.parameters)
        .map(([key, value]) => `  - ${key}: ${value}`)
        .join('\n')
      
      return `${tool.name}:\n  ì„¤ëª…: ${tool.description}\n  íŒŒë¼ë¯¸í„°:\n${params}`
    }).join('\n\n')
  }
  
  async execute(userRequest: string): Promise<string> {
    console.log(`\nğŸ¤– ì‚¬ìš©ì ìš”ì²­: ${userRequest}\n`)
    
    // Step 1: ë„êµ¬ ì„ íƒ
    const planPrompt = `
ë‹¹ì‹ ì€ AI ê°œë°œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ìš”ì²­: "${userRequest}"

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
${this.getToolsDescription()}

ìœ„ ìš”ì²­ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{
  "tool": "ë„êµ¬ëª…",
  "params": ["param1", "param2", ...]
}

ë§Œì•½ ë„êµ¬ê°€ í•„ìš” ì—†ë‹¤ë©´:
{
  "tool": "none",
  "response": "ì§ì ‘ ë‹µë³€"
}
`
    
    console.log('ğŸ” ë„êµ¬ ì„ íƒ ì¤‘...')
    const planResponse = await this.llm.generate(planPrompt)
    console.log('ğŸ“‹ ê³„íš:', planResponse)
    
    try {
      // JSON ì¶”ì¶œ (```json ... ``` ì œê±°)
      const jsonMatch = planResponse.match(/\{[\s\S]*\}/)
      if (!jsonMatch) {
        throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
      }
      
      const plan = JSON.parse(jsonMatch[0])
      
      // Step 2: ë„êµ¬ ì‹¤í–‰
      if (plan.tool === 'none') {
        return plan.response
      }
      
      const tool = tools.find(t => t.name === plan.tool)
      if (!tool) {
        return `ì—ëŸ¬: ë„êµ¬ '${plan.tool}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`
      }
      
      console.log(`âš¡ ë„êµ¬ ì‹¤í–‰: ${tool.name}(${plan.params.join(', ')})`)
      const result = await tool.execute(...plan.params)
      console.log('âœ… ì‹¤í–‰ ê²°ê³¼:', result.substring(0, 200) + '...')
      
      // Step 3: ê²°ê³¼ ì •ë¦¬
      const summaryPrompt = `
ì‚¬ìš©ì ìš”ì²­: "${userRequest}"
ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:
${result}

ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
`
      
      const summary = await this.llm.generate(summaryPrompt)
      return summary
      
    } catch (error) {
      console.error('âŒ ì—ëŸ¬:', error.message)
      return `ì—ëŸ¬: ${error.message}`
    }
  }
  
  async chat(message: string): Promise<string> {
    this.conversationHistory.push({
      role: 'user',
      content: message
    })
    
    const response = await this.execute(message)
    
    this.conversationHistory.push({
      role: 'assistant',
      content: response
    })
    
    return response
  }
}
```

#### `src/index.ts` - ë©”ì¸

```typescript
import { OllamaAgent } from './agent'
import * as readline from 'readline'

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
})

const agent = new OllamaAgent('qwen2.5:7b', 'http://localhost:11434')

console.log('ğŸ¤– Ollama Agent ì‹œì‘!')
console.log('   Ollamaê°€ http://localhost:11434 ì—ì„œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.')
console.log('   ì¢…ë£Œí•˜ë ¤ë©´ "exit" ì…ë ¥\n')

function ask() {
  rl.question('ğŸ‘¤ You: ', async (input) => {
    if (input.toLowerCase() === 'exit') {
      console.log('ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤!')
      rl.close()
      return
    }
    
    try {
      const response = await agent.chat(input)
      console.log(`\nğŸ¤– Agent: ${response}\n`)
    } catch (error) {
      console.error(`âŒ ì—ëŸ¬: ${error.message}\n`)
    }
    
    ask()
  })
}

ask()
```

### ì‚¬ìš© ë°©ë²•

```bash
# 1. Ollama ì„œë²„ ì‹œì‘ (PowerShell 1)
ollama serve

# 2. Agent ì‹¤í–‰ (PowerShell 2)
cd ollama-agent
npx ts-node src/index.ts

# 3. ì‚¬ìš©!
ğŸ‘¤ You: README.md íŒŒì¼ì„ ì½ì–´ì¤˜
ğŸ¤– Agent: [íŒŒì¼ ë‚´ìš© ì¶œë ¥]

ğŸ‘¤ You: package.json íŒŒì¼ì„ ë§Œë“¤ì–´ì¤˜
ğŸ¤– Agent: [íŒŒì¼ ìƒì„± ì™„ë£Œ]

ğŸ‘¤ You: git status í™•ì¸í•´ì¤˜
ğŸ¤– Agent: [Git ìƒíƒœ ì¶œë ¥]
```

---

## ğŸ¦œ ë°©ë²• 2: LangChain ì‚¬ìš© (ì¶”ì²œ!)

### ì„¤ì¹˜

```bash
npm install langchain @langchain/community @langchain/core
```

### ì½”ë“œ

```typescript
import { ChatOllama } from '@langchain/community/chat_models/ollama'
import { DynamicTool } from '@langchain/core/tools'
import { AgentExecutor, createReactAgent } from 'langchain/agents'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { readFileSync, writeFileSync } from 'fs'
import { exec } from 'child_process'
import { promisify } from 'util'

const execAsync = promisify(exec)

// LLM ì„¤ì •
const llm = new ChatOllama({
  baseUrl: 'http://localhost:11434',
  model: 'qwen2.5:7b'
})

// ë„êµ¬ ì •ì˜
const tools = [
  new DynamicTool({
    name: 'read_file',
    description: 'íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤. ì…ë ¥: íŒŒì¼ ê²½ë¡œ',
    func: async (path: string) => {
      return readFileSync(path, 'utf-8')
    }
  }),
  
  new DynamicTool({
    name: 'write_file',
    description: 'íŒŒì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤. ì…ë ¥: JSON {"path": "ê²½ë¡œ", "content": "ë‚´ìš©"}',
    func: async (input: string) => {
      const { path, content } = JSON.parse(input)
      writeFileSync(path, content, 'utf-8')
      return `íŒŒì¼ ì‘ì„± ì™„ë£Œ: ${path}`
    }
  }),
  
  new DynamicTool({
    name: 'run_command',
    description: 'ì‰˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì…ë ¥: ëª…ë ¹ì–´',
    func: async (command: string) => {
      const { stdout, stderr } = await execAsync(command)
      return stdout || stderr
    }
  })
]

// Prompt í…œí”Œë¦¿
const prompt = ChatPromptTemplate.fromMessages([
  ['system', `ë‹¹ì‹ ì€ AI ê°œë°œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {tools}
ë„êµ¬ ì´ë¦„: {tool_names}

ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.`],
  ['human', '{input}'],
  ['assistant', '{agent_scratchpad}']
])

// Agent ìƒì„±
const agent = await createReactAgent({
  llm,
  tools,
  prompt
})

const agentExecutor = new AgentExecutor({
  agent,
  tools,
  verbose: true
})

// ì‹¤í–‰
const result = await agentExecutor.invoke({
  input: 'README.md íŒŒì¼ì„ ì½ì–´ì¤˜'
})

console.log(result.output)
```

---

## ğŸŒ ë°©ë²• 3: Open WebUI ì‚¬ìš©

### Docker ì„¤ì¹˜

```bash
docker run -d -p 3000:8080 \
  -e OLLAMA_BASE_URL=http://host.docker.internal:11434 \
  -v open-webui:/app/backend/data \
  --name open-webui \
  ghcr.io/open-webui/open-webui:main
```

### ì‚¬ìš©

1. ë¸Œë¼ìš°ì €: http://localhost:3000
2. íšŒì›ê°€ì…/ë¡œê·¸ì¸
3. ì„¤ì • â†’ ëª¨ë¸ â†’ Ollama ëª¨ë¸ ì„ íƒ (qwen2.5:7b)
4. ChatGPTì²˜ëŸ¼ ì‚¬ìš©!

### ê¸°ëŠ¥

- âœ… íŒŒì¼ ì—…ë¡œë“œ
- âœ… ì½”ë“œ ì‹¤í–‰ í”ŒëŸ¬ê·¸ì¸
- âœ… ì›¹ ê²€ìƒ‰
- âœ… ëŒ€í™” ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°

---

## ğŸ’» ë°©ë²• 4: Continue.dev ì‚¬ìš©

### ì„¤ì¹˜

1. VS Code ì—´ê¸°
2. Extensions â†’ "Continue" ê²€ìƒ‰ â†’ ì„¤ì¹˜
3. Continue ì„¤ì • ì—´ê¸° (Ctrl+Shift+P â†’ "Continue: Open Config")

### ì„¤ì •

```json
{
  "models": [
    {
      "title": "Qwen 2.5:7B",
      "provider": "ollama",
      "model": "qwen2.5:7b"
    }
  ],
  "tabAutocompleteModel": {
    "title": "Qwen",
    "provider": "ollama",
    "model": "qwen2.5:7b"
  }
}
```

### ì‚¬ìš©

```typescript
// 1. ì½”ë“œ ì‘ì„± ì¤‘
function calculateSum(a, b) {
  // ì—¬ê¸°ì„œ Ctrl+I
  // â†’ "íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ë¡œ ë³€í™˜í•´ì¤˜"
  // â†’ Continueê°€ ìë™ìœ¼ë¡œ ë³€í™˜!
}

// 2. íŒŒì¼ ì„ íƒ
// Ctrl+L â†’ íŒŒì¼ ì¶”ê°€
// "ì´ íŒŒì¼ì„ ë¦¬íŒ©í† ë§í•´ì¤˜"
// â†’ ìë™ ìˆ˜ì •!
```

---

## ğŸ”§ ë°©ë²• 5: Aider ì‚¬ìš© (ìµœê³  ì¶”ì²œ!)

### ì„¤ì¹˜

```bash
# Python í•„ìš”
pip install aider-chat
```

### ì‚¬ìš©

```bash
$ aider --model ollama/qwen2.5:7b

Aider v0.52.0
Main model: ollama/qwen2.5:7b with whole edit format
Git repo: .git
Repo-map: disabled
Added README.md to the chat

> README.mdì— ì„¤ì¹˜ ê°€ì´ë“œë¥¼ ì¶”ê°€í•´ì¤˜

[Aiderê°€ ìë™ìœ¼ë¡œ íŒŒì¼ ìˆ˜ì •]
[Git ì»¤ë°‹ ìë™ ìƒì„±]

> ì´ì œ src/index.ts íŒŒì¼ì„ ë§Œë“¤ì–´ì¤˜

[íŒŒì¼ ìƒì„± ë° ì»¤ë°‹]

> ë°©ê¸ˆ ë§Œë“  íŒŒì¼ì— Express ì„œë²„ ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜

[ì½”ë“œ ì‘ì„± ë° ì»¤ë°‹]
```

### íŠ¹ì§•

- âœ… Git ìë™ í†µí•©
- âœ… ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ìˆ˜ì •
- âœ… ìë™ ì»¤ë°‹
- âœ… í„°ë¯¸ë„ì—ì„œ ë°”ë¡œ ì‚¬ìš©
- âœ… ë§¤ìš° ë¹ ë¦„

---

## ğŸš€ ì‹¤ì „ í”„ë¡œì íŠ¸: ë‚˜ë§Œì˜ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸

### í”„ë¡œì íŠ¸ ëª©í‘œ

Claudeì²˜ëŸ¼ ëŒ€í™”í•˜ë©´ì„œ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” í„°ë¯¸ë„ ì•± ë§Œë“¤ê¸°!

### ìµœì¢… ì½”ë“œ (ìœ„ ë°©ë²• 1 ì°¸ì¡°)

### ì‹¤í–‰

```bash
# Terminal 1: Ollama ì„œë²„
ollama serve

# Terminal 2: Agent ì‹¤í–‰
cd ollama-agent
npx ts-node src/index.ts
```

### ë°ëª¨

```bash
ğŸ¤– Ollama Agent ì‹œì‘!

ğŸ‘¤ You: ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜. express-appì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ

ğŸ¤– Agent: 
   âœ… ë””ë ‰í† ë¦¬ ìƒì„±: express-app
   âœ… package.json ìƒì„± ì™„ë£Œ
   âœ… src/index.ts ìƒì„± ì™„ë£Œ
   âœ… Git ì´ˆê¸°í™” ì™„ë£Œ
   
   í”„ë¡œì íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!

ğŸ‘¤ You: src/index.tsì— Express ì„œë²„ ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜

ğŸ¤– Agent:
   âœ… Express ì„œë²„ ì½”ë“œ ì‘ì„± ì™„ë£Œ
   âœ… Git ì»¤ë°‹: "feat: Add Express server"
   
   ì„œë²„ê°€ í¬íŠ¸ 3000ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤!

ğŸ‘¤ You: npm installì„ ì‹¤í–‰í•´ì¤˜

ğŸ¤– Agent:
   âš¡ ëª…ë ¹ì–´ ì‹¤í–‰ ì¤‘...
   âœ… Express, TypeScript ì„¤ì¹˜ ì™„ë£Œ!
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| ë°©ë²• | ì„¤ì • ì‹œê°„ | ì‘ë‹µ ì†ë„ | ê¸°ëŠ¥ | ì¶”ì²œë„ |
|------|-----------|-----------|------|--------|
| **ì§ì ‘ êµ¬í˜„** | 2-3ì‹œê°„ | 3-5ì´ˆ | ì»¤ìŠ¤í…€ | â­â­â­ |
| **LangChain** | 30ë¶„ | 3-5ì´ˆ | í’ë¶€ | â­â­â­â­â­ |
| **Open WebUI** | 5ë¶„ | 2-3ì´ˆ | ê¸°ë³¸ | â­â­â­â­ |
| **Continue.dev** | 5ë¶„ | 1-2ì´ˆ | VS Code | â­â­â­â­ |
| **Aider** | 2ë¶„ | 2-3ì´ˆ | Git ìµœê³  | â­â­â­â­â­ |

---

## ğŸ’¡ ìµœì¢… ì¶”ì²œ

### ì´ˆë³´ì
â†’ **Open WebUI** ë˜ëŠ” **Continue.dev**

### ê°œë°œì
â†’ **Aider** (Git í†µí•© ìµœê³ !)

### ê³ ê¸‰ ì‚¬ìš©ì
â†’ **LangChain** (ì™„ì „ ì»¤ìŠ¤í„°ë§ˆì´ì§•)

---

## ğŸ¯ ìš”ì•½

```
ì§ˆë¬¸: "Ollamaë¥¼ AI ê°œë°œìë¡œ ë§Œë“¤ë ¤ë©´?"

ë‹µë³€:
1. ë„êµ¬ ì‹œìŠ¤í…œì„ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤!
2. ê°€ì¥ ì‰¬ìš´ ë°©ë²•: Aider ì‚¬ìš©
3. ê°€ì¥ ê°•ë ¥í•œ ë°©ë²•: LangChain ì‚¬ìš©
4. ê°€ì¥ UI ì¢‹ì€ ë°©ë²•: Open WebUI ì‚¬ìš©

ì¶”ì²œ:
â†’ ì§€ê¸ˆ ë°”ë¡œ: Aider ì„¤ì¹˜ í›„ ì‚¬ìš©!
â†’ ë‚˜ì¤‘ì—: LangChainìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§•!
```

---

**ìƒì„±ì¼**: 2026-02-02  
**ë²„ì „**: 1.0.0
